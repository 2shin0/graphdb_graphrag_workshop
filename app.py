from dotenv import load_dotenv
import os

from neo4j import GraphDatabase, basic_auth
import openai

from neo4j_graphrag.retrievers import Text2CypherRetriever
from neo4j_graphrag.llm import OpenAILLM

from neo4j import GraphDatabase

from neo4j_graphrag.generation import GraphRAG

import gradio as gr

from make_schema import get_schema, format_schema
from content import lecture, structure, cypher

def ready_gpt(user_api_key):
    try:
        driver = GraphDatabase.driver(
        "bolt://184.72.178.158:7687",
        auth=basic_auth("neo4j", "formulas-method-blood"))

        llm = OpenAILLM(model_name="gpt-4o", model_params={"temperature": 0}, api_key = user_api_key)
        test_prompt = "Hello! How are you?"
        response = llm.invoke(test_prompt).content
        if response:  # LLM ì—°ê²° ì„±ê³µ
            print(response)
            
            # Neo4j Schema ê°€ì ¸ì˜¤ê¸° ë° í¬ë§·
            schema = get_schema("bolt://184.72.178.158:7687", "neo4j", "formulas-method-blood")
            neo4j_schema = format_schema(schema)

            # LLM INPUT / QUERY ì˜ˆì‹œ
            examples = [
                """USER INPUT: 'ë°°ìˆ˜ì§€ê°€ í’€ì—ˆë˜ ë¬¸ì œ ì½”ë“œì™€ ë¬¸ì œ ì§ˆë¬¸ì„ ì•Œë ¤ì£¼ì„¸ìš”.'
                QUERY: MATCH (p:Person {name:'ë°°ìˆ˜ì§€'})-[r:SOLVED]->(q:Question)
                RETURN q.code, q.question LIMIT 10""",

                """USER INPUT: 'ë°°ìˆ˜ì§€ê°€ ì•„ì§ í’€ì§€ ì•Šì€ ë¬¸ì œ ì½”ë“œì™€ ë¬¸ì œ ì§ˆë¬¸ì„ í™•ì¸í•  ìˆ˜ ìˆì„ê¹Œìš”?'
                QUERY: MATCH (p:Person {name:'ë°°ìˆ˜ì§€'})-[r:UNSOLVED]->(q:Question)
                RETURN q.code, q.question""",

                """USER INPUT: '4í•™ë…„ í•™ìƒë“¤ì´ í’€ì—ˆë˜ ì§ˆë¬¸ì˜ í‰ê·  ì ìˆ˜ëŠ” ì–¼ë§ˆì¸ê°€ìš”?'
                QUERY: MATCH (g:Grade {grade:'4'})<-[:belongs_to]-(p:Person)-[r:SOLVED]->(q:Question)
                RETURN AVG(r.score) AS avgScore""",

                """USER INPUT: '4í•™ë…„ í•™ìƒë“¤ì´ ê°€ì¥ ë§ì´ í‘¼ ì§ˆë¬¸ì„ ì•Œê³  ì‹¶ì–´ìš”.'
                QUERY: MATCH (g:Grade {grade:'4'})<-[:belongs_to]-(p:Person)-[r:SOLVED]->(q:Question)
                RETURN q.code, q.question, COUNT(r) AS solveCount
                ORDER BY solveCount DESC LIMIT 1""",

                """USER INPUT: '4í•™ë…„ í•™ìƒë“¤ì´ ê°€ì¥ ì˜¤ëœ ì‹œê°„ í’€ì—ˆë˜ ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?'
                QUERY: MATCH (g:Grade {grade:'4'})<-[:belongs_to]-(p:Person)-[s:SOLVED]->(q:Question)
                RETURN q.code, q.question, AVG(s.time_taken) AS avgTime
                ORDER BY avgTime DESC LIMIT 1""",

                """USER INPUT: '4í•™ë…„ í•™ìƒë“¤ì´ í‘¼ ì§ˆë¬¸ ì¤‘ ì •ë‹µë¥ ì´ ê°€ì¥ ë†’ì€ ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?'
                QUERY: MATCH (g:Grade {grade:'4'})<-[:belongs_to]-(p:Person)-[r:SOLVED]->(q:Question)
                RETURN q.code, q.question, AVG(r.is_correct) AS correctRate
                ORDER BY correctRate DESC LIMIT 1""",

                """USER INPUT: 'ëŒ€ì£¼ì œ ë¶„ìˆ˜ì˜ ë§ì…ˆê³¼ ëº„ì…ˆì— í•´ë‹¹í•˜ëŠ” ë¬¸ì œì˜ ì§ˆë¬¸ 5ê°œë¥¼ ì•Œê³  ì‹¶ì–´ìš”.'
                QUERY: MATCH (m:MainTopic {name:'ë¶„ìˆ˜ì˜ ë§ì…ˆê³¼ ëº„ì…ˆ'})-[r:has_question]->(q:Question)
                RETURN q.code, q.question LIMIT 5""",

                """USER INPUT: 'ë°°ìˆ˜ì§€ê°€ í‘¼ ë¬¸ì œ ì¤‘ í”¼ë“œë°±ì´ í¬í•¨ëœ ë¬¸ì œì˜ ì§ˆë¬¸ì„ ì•Œë ¤ì£¼ì„¸ìš”.'
                QUERY: MATCH (p:Person {name: 'ë°°ìˆ˜ì§€'})-[r:SOLVED]->(q:Question)
                WHERE r.feedback IS NOT NULL
                RETURN p, r, q""",

                """USER INPUT: '4í•™ë…„ í•™ìƒë“¤ì´ ëŒ€ì£¼ì œ ì•½ìˆ˜ì™€ ë°°ìˆ˜ì˜ ë¬¸ì œë¥¼ ì–¼ë§ˆë‚˜ í’€ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‚˜ìš”?'
                QUERY: MATCH (g:Grade {grade:'4'})<-[:belongs_to]-(p:Person)-[s:SOLVED]->(q:Question)<-[:has_question]-(m:MainTopic {name:'í°ìˆ˜'})
                RETURN COUNT(s) AS solveCount"""

                """USER INPUT: 'ì†Œìˆ˜ì˜ ë‚˜ëˆ—ì…ˆ ë¬¸ì œë¥¼ ì˜ ëª»í‘¸ëŠ” í•™ìƒì€ ì–´ëŠ ëŒ€ì£¼ì œë¥¼ ë‹¤ì‹œ ê³µë¶€í•´ì•¼ í•´?'
                QUERY: MATCH (relatedTopic:MainTopic)-[:precedes*]->(t:MainTopic {name: 'ì†Œìˆ˜ì˜ ë‚˜ëˆ—ì…ˆ'})
                RETURN relatedTopic.name;
                """

                """USER INPUT: 'ë³€ìš°ì„ í•™ìƒ ì·¨ì•½ ê°œë… ë¬¸ì œ ì¶”ì²œí•´ì¤˜'
                QUERY: MATCH (p:Person {name: 'ë³€ìš°ì„'})-[:SOLVED]->(q:Question)<-[:has_question]-(mt:MainTopic)
                MATCH (p)-[s:SOLVED]->(q)
                WITH mt, AVG(s.score) AS avg_score
                ORDER BY avg_score ASC
                LIMIT 1
                WITH mt AS LowestAvgMainTopic, avg_score
                MATCH (p:Person {name: 'ë³€ìš°ì„'})-[:UNSOLVED]->(q:Question)<-[:has_question]-(LowestAvgMainTopic)
                RETURN LowestAvgMainTopic.name AS LowestAvgMainTopic, avg_score, q.question AS UnsolvedQuestions
                """
            ]

            # Text2CypherRetriever ì´ˆê¸°í™”
            retriever = Text2CypherRetriever(
                driver=driver,
                llm=llm,
                neo4j_schema=neo4j_schema,
                examples=examples,
            )

            # GraphRAG ì´ˆê¸°í™”
            rag = GraphRAG(retriever=retriever, llm=llm)

            return {"llm": llm, "retriever": retriever, "rag": rag}, "ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!"
        else:
            raise Exception("LLM ì—°ê²° ì‹¤íŒ¨")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"llm": None, "retriever": None, "rag": None}, "API Keyë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”!"

def generate_query(browser_state, text_input):
    retriever = browser_state["retriever"]

    search_result = retriever.search(query_text=text_input)
    return search_result.metadata['cypher']

def default_llm(browser_state, message):
    llm = browser_state["llm"]

    prompt_text = f"""
    ë‹¹ì‹ ì€ ì´ˆë“±í•™êµ ë³´ì¡° êµì‚¬ ì±—ë´‡ì…ë‹ˆë‹¤. user_inputì— ëŒ€ë‹µí•˜ë˜ ë§Œì•½ GraphDB ì† ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì´ë¼ë©´ ê·¸ ì§ˆë¬¸ì— ëŒ€í•´ ìì„¸í•œ ì •ë³´ë¥¼ ë‹µ í•´ì£¼ì„¸ìš”.
    ê·¸ë¦¬ê³  í•™ë…„, í•™ìƒ ì´ë¦„, ëŒ€ì£¼ì œ ì´ë¦„, í•„í„°ë§ ê¸°ì¤€ì„ ì •í™•íˆ ë§í•˜ë¼ê³  ê¶Œê³ í•´ ë³´ì„¸ìš”.
    user_input : {message}
    """
    return llm.invoke(prompt_text).content

def intent_detection(browser_state, message):
    llm = browser_state["llm"]

    prompt_text = f"""
    ì£¼ì–´ì§„ query_text ê°€ í•™ë…„, í•™ìƒ, ëŒ€ì£¼ì œ, ë¬¸ì œì— ëŒ€í•œ ë‹µë³€ì„ ë°›ê¸° ìœ„í•œ ë³¸ê²©ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë³´ì´ë©´ Trueë¥¼ ë°˜í™˜í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Falseë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”.
    query_text : {message}
    """
    return llm.invoke(prompt_text).content == 'True'

def response(browser_state, message, chat_history):
    llm = browser_state["llm"]

    if(intent_detection(browser_state, message)):
        rag = browser_state["rag"]
        
        rag_result = rag.search(query_text=message
                                + "(Please also provide evidence for how you used context in your answer. YOU MUST ANSWER in KOREAN PLEASE.)"
                                , return_context = True)
        chat_history.append((message, rag_result.answer))
        return chat_history, rag_result.retriever_result.metadata['cypher'], rag_result.retriever_result.items
    else:
        llm_result = default_llm(browser_state, message)
        chat_history.append((message, llm_result))
        return chat_history, "í•™ë…„, í•™ìƒ, ëŒ€ì£¼ì œ, ë¬¸ì œ ê´€ë ¨ ì§ˆë¬¸ì´ì—ˆì–´ìš”.", llm_result

with gr.Blocks(theme=gr.themes.Soft(font=[gr.themes.GoogleFont("Noto Sans Korean")], text_size=gr.themes.sizes.text_lg)) as demo:
    gr.HTML("""
        <div style="text-align: center; max-width: 1000px; margin: 20px auto;">
            <h1>ğŸ”— GraphRAG ì‹¤ìŠµ ì›Œí¬ìˆ</h1>
        </div>
        """)
    browser_state = gr.State({"llm": None, "retriever": None, "rag": None})

    with gr.Tabs():
        with gr.Tab("API Key ë“±ë¡"):
            with gr.Row():
                user_api_key = gr.Textbox(label="API Key", placeholder="API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.", lines=1)
                api_btn = gr.Button("Upload", variant="primary")
            output_text = gr.Textbox(label="API Key ë“±ë¡ ê²°ê³¼", interactive=False)
            api_btn.click(ready_gpt, inputs=user_api_key, outputs = [browser_state, output_text])

        with gr.Tab("ê°•ì˜ì•ˆ"):
            gr.HTML(
                lecture
            )

        with gr.Tab("DB êµ¬ì¡°ë„"):
            gr.HTML(
                structure
            )
        
            gr.Markdown(
                cypher
            )
            
            gr.Button(value='GraphDB ë°”ë¡œê°€ê¸°', link='http://184.72.178.158:7474', variant='primary')
        
        with gr.Tab("ì˜ˆì œ ìƒì„±ê¸°"):
            with gr.Row():
                text_input = gr.Textbox(label="ì§ˆë¬¸", placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.", lines=2)

                with gr.Column(scale=0):
                  btn = gr.Button("ì¿¼ë¦¬ ìƒì„±", variant="primary")
                  clear = gr.Button("Clear")

            output = gr.Textbox(label="ìƒì„±ëœ Cypher ì¿¼ë¦¬", placeholder="ì—¬ê¸°ì— ì¿¼ë¦¬ê°€ í‘œì‹œë©ë‹ˆë‹¤.", lines=6)
      
            btn.click(generate_query, inputs=[browser_state,text_input], outputs=output)
            clear.click(lambda: None, None, queue=False)

            with gr.Row():
                gr.Button(value='íŒ¨ë“¤ë¦¿ ë°”ë¡œê°€ê¸°', link='https://padlet.com/02shin00/snu_workshop', variant='primary')

        with gr.Tab("ì±—ë´‡"):
            with gr.Row():
                with gr.Column(scale=0):
                    generated_query = gr.Textbox(label="ìƒì„±ëœ Cypher ì¿¼ë¦¬")
                    query_result = gr.Textbox(label="ì¿¼ë¦¬ ì¡°íšŒ ê²°ê³¼")

                chatbot = gr.Chatbot()

            with gr.Row():
                with gr.Column():
                    msg = gr.Textbox(
                        placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.",
                        label="ì…ë ¥",
                    )
                with gr.Column(scale=0):
                    btn = gr.Button("Submit", variant="primary")
                    clear = gr.Button("Clear")

            with gr.Row():
                examples = gr.Examples(
                    examples=[
                        "3í•™ë…„ í•™ìƒë“¤ì´ ê°€ì¥ ë§ì´ í‘¼ ë¬¸ì œì˜ ëŒ€ì£¼ì œë¥¼ ì•Œë ¤ì¤˜.",
                        "ë°°ìˆ˜ì§€ í•™ìƒì´ í’€ì§€ ì•Šì€ ë¬¸ì œ ì¤‘ í•™ìƒë“¤ì´ ë§ì´ í‘¼ ë¬¸ì œ 3ê°œëŠ” ë­ì•¼?",
                    ],
                    inputs=[msg]
                )

            btn.click(fn=response, inputs=[browser_state, msg, chatbot], outputs=[chatbot, generated_query, query_result])
            msg.submit(response, [browser_state, msg, chatbot], [chatbot, generated_query, query_result])
            clear.click(lambda: None, None, msg, queue=False)

demo.launch(debug=True, share=True)
